# Local Chat App mit SQLite

Eine vollstÃ¤ndig lokale Chat-Anwendung mit LLM und Vektorsuche, ohne Cloud-AbhÃ¤ngigkeiten oder API-Kosten, die SQLite anstelle von Qdrant verwendet.

## ğŸ¯ Beschreibung

Diese Anwendung ist eine leistungsstarke, kostengÃ¼nstige Alternative zu Cloud-basierten Chatbot-LÃ¶sungen wie Azure OpenAI. Sie bietet eine moderne, benutzerfreundliche OberflÃ¤che fÃ¼r die Interaktion mit Ihren eigenen Dokumenten durch lokale Sprachmodelle (LLMs) und ermÃ¶glicht semantische Suche ohne AbhÃ¤ngigkeit von externen Diensten oder API-Kosten.

Im Vergleich zur ursprÃ¼nglichen Local-Chat-App verwendet diese Version SQLite anstelle von Qdrant, was die Installation vereinfacht, da keine Docker-Installation erforderlich ist.

## ğŸ“‹ Features

- **Lokale Sprachmodelle**: Integration mit Ollama fÃ¼r vollstÃ¤ndig lokale LLM-AusfÃ¼hrung
- **Intelligente Modellverwaltung**: Automatische Hardwareerkennung und Modellempfehlungen
- **Semantische Vektorsuche**: Leistungsstarke SQLite-Integration mit Vektoreinbettungen
- **Online Dokumentenverwaltung**: Hochladen und Organisieren von Dokumenten direkt Ã¼ber die BenutzeroberflÃ¤che
- **Dokumentenreferenzierung**: Indizierung von PDF-, Word- und Textdateien mit Quellenangaben
- **Moderne Chat-UI**: Responsive BenutzeroberflÃ¤che mit Echtzeit-Interaktionen
- **Automatische Quellenangaben**: Alle aus Dokumenten stammenden Informationen werden mit Quellen zitiert
- **Fallback zu allgemeinem Wissen**: Kennzeichnung von Antworten aus dem Modellwissen vs. Dokumentenwissen
- **Token-Limitierung**: Intelligente Verwaltung von KontextgrÃ¶ÃŸe fÃ¼r optimale Leistung
- **Keine Docker-AbhÃ¤ngigkeit**: Verwendet SQLite anstelle von Qdrant fÃ¼r die Vektordatenbank
- **Verbesserter System-Prompt**: Optimierte Anweisungen fÃ¼r prÃ¤zisere und informativere Antworten

## ğŸ¤” Warum Local Chat App mit SQLite?

### ğŸ’» Einfachere Installation
- **Keine Docker-AbhÃ¤ngigkeit**: Keine Notwendigkeit, Docker zu installieren und zu konfigurieren
- **Alles in einem Paket**: SQLite ist in die Anwendung integriert, keine separaten Services

### ğŸ’° Kosteneinsparung
- **Keine API-Kosten**: Azure OpenAI berechnet pro Token (Eingabe und Ausgabe)
- **Keine Ãœberraschungen**: Keine unerwarteten Rechnungen durch intensive Nutzung

### ğŸ›¡ï¸ Datenschutz und Kontrolle
- **Daten bleiben lokal**: Alle Dokumente und Anfragen bleiben in Ihrer Kontrolle
- **Keine Datenbereitstellung**: Ihre Unternehmensdaten werden nicht fÃ¼r AI-Training verwendet

### ğŸš€ Leistung und Anpassbarkeit
- **Modellauswahl**: FlexibilitÃ¤t beim Wechsel zwischen verschiedenen Modellen
- **Angepasste Systemanforderungen**: Auswahl von Modellen basierend auf Ihrer Hardware
- **VollstÃ¤ndige Anpassungskontrolle**: Ã„ndern Sie den Code nach Ihren BedÃ¼rfnissen

### ğŸ”Œ OfflinefÃ¤higkeit
- **Keine InternetabhÃ¤ngigkeit**: Funktioniert vollstÃ¤ndig ohne Internetverbindung
- **Keine Ausfallzeiten**: Nicht betroffen von Cloud-Dienst-Unterbrechungen

## ğŸ“Œ Neue Features in dieser Version

### ğŸ“ Online Dokumentenverwaltung
- **Web-Interface zum Hochladen**: Einfaches Hochladen von Dokumenten Ã¼ber die WeboberflÃ¤che
- **Kategorisierung und Tagging**: Organisieren Sie Dokumente mit Kategorien und Tags
- **Metadaten-Management**: Beschreibungen und Details zu Dokumenten hinzufÃ¼gen
- **Indexierungsstatus**: Ãœberwachen Sie den Status der Dokumentindexierung
- **Re-Indexierung**: Aktualisieren Sie Dokumente bei Bedarf

### ğŸ§  Verbesserter System-Prompt
- **PrÃ¤zisere Anweisungen**: Optimierte Anweisungen fÃ¼r genauere Quellenangaben
- **Informative Antworten**: Fokus auf klare und strukturierte Informationen
- **Deutliche Kennzeichnung**: Klar erkennbare Unterscheidung zwischen Dokumentenwissen und allgemeinem Wissen

## ğŸ› ï¸ Technologie-Stack

### Frontend
- HTML5, CSS3 mit Custom Properties und responsivem Design
- Vanilla JavaScript ohne externe Frameworks

### Backend
- Node.js mit Express
- Ollama fÃ¼r lokale LLM-Integration
- SQLite fÃ¼r Vektordatenbank und Dokumentenverwaltung
- Multer fÃ¼r Datei-Upload-Handling
- Transformers.js fÃ¼r Einbettungen

## ğŸš€ Erste Schritte

Eine detaillierte Installations- und Benutzungsanleitung finden Sie in der [INSTALLATION.md](INSTALLATION.md).

## ğŸ§  Wie funktioniert die SQLite Vektordatenbank?

Diese Version der Local Chat App verwendet SQLite anstelle von Qdrant fÃ¼r die Speicherung und Suche von Vektoreinbettungen. Dies bietet mehrere Vorteile:

1. **Einfachere Installation**: Keine Docker-Installation erforderlich
2. **Verringerte Systemanforderungen**: SQLite ist leichtgewichtiger als Qdrant
3. **Integrierte Datenbank**: Die Datenbank ist direkt in die Anwendung eingebettet

Die Vektorsuche wird durch eine Kombination aus effizienter Datenbankabfragen und Vektor-Ã„hnlichkeitsberechnungen in JavaScript implementiert. Obwohl diese LÃ¶sung mÃ¶glicherweise nicht so performant wie Qdrant ist, bietet sie fÃ¼r die meisten AnwendungsfÃ¤lle ausreichende Leistung und vereinfacht die Installation und Wartung erheblich.

## ğŸ“Š Leistungsvergleich

| Funktion | SQLite-Version | Qdrant-Version | Azure OpenAI |
|---|---|---|---|
| Installation | Einfach, keine Docker-AbhÃ¤ngigkeit | Erfordert Docker | Cloud-Dienst |
| Vektorsuche | Gut | Sehr gut | Sehr gut |
| Dokumentenverwaltung | Web-Interface | Nur lokal | Web-Interface |
| Kosten | Einmalige Hardware-Kosten | Einmalige Hardware-Kosten | Fortlaufende API-Kosten |
| Latenz | AbhÃ¤ngig von lokaler Hardware | AbhÃ¤ngig von lokaler Hardware | AbhÃ¤ngig von Internetverbindung |
| Datenschutz | 100% lokal | 100% lokal | Daten werden an Azure gesendet |
| Anpassbarkeit | VollstÃ¤ndiger Code-Zugriff | VollstÃ¤ndiger Code-Zugriff | Begrenzt auf API-Parameter |
| Offlinebetrieb | VollstÃ¤ndig offlinefÃ¤hig | VollstÃ¤ndig offlinefÃ¤hig | Erfordert Internetverbindung |

## ğŸ”§ Konfiguration

Die Anwendung ist hochgradig konfigurierbar durch Umgebungsvariablen. Detaillierte Informationen finden Sie in der `.env.example`-Datei.

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe die [LICENSE](LICENSE) Datei fÃ¼r Details.